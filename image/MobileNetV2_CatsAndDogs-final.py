# %% [markdown]
# # ğŸ±ğŸ¶ MobileNetV2ë¥¼ í™œìš©í•œ ê³ ì–‘ì´/ê°œ ë¶„ë¥˜ í”„ë¡œì íŠ¸
# 
# ## í”„ë¡œì íŠ¸ ê°œìš”
# - **ëª©í‘œ**: MobileNetV2 ì‚¬ì „í›ˆë ¨ ëª¨ë¸ì„ í™œìš©í•œ Transfer Learningìœ¼ë¡œ ê³ ì–‘ì´/ê°œ ì´ë¯¸ì§€ ë¶„ë¥˜
# - **ë°ì´í„°ì…‹**: Googleì˜ cats_and_dogs_filtered ë°ì´í„°ì…‹
# - **ëª¨ë¸**: MobileNetV2 (ImageNet ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
# - **ê¸°ë²•**: Transfer Learning & Fine-tuning

# %% [markdown]
# ## A. ë°ì´í„°ì…‹ ì¤€ë¹„ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

# %% [markdown]
# ### 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

# %%
# ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (Colab í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰)
# ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”
import os
import sys

# Colab í™˜ê²½ í™•ì¸
try:
    import google.colab
    IN_COLAB = True
    print("ğŸ” Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
except ImportError:
    IN_COLAB = False
    print("ğŸ” ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")

# Colabì—ì„œë§Œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
if IN_COLAB:
    # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    os.system('wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip')
    os.system('unzip cats_and_dogs_filtered.zip')
else:
    print("ğŸ“¥ ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ë‹¤ìŒ ë§í¬ì—ì„œ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”:")
    print("https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip")

# %%
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os
from glob import glob
from PIL import Image
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

print("ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!")
print(f"ğŸ”§ TensorFlow ë²„ì „: {tf.__version__}")

# %%
# ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸ ë° ì„¤ì •
if IN_COLAB:
    # Colab í™˜ê²½ì—ì„œì˜ ê²½ë¡œ
    base_path = '/content/cats_and_dogs_filtered'
else:
    # ë¡œì»¬ í™˜ê²½ì—ì„œì˜ ê²½ë¡œ (ì‚¬ìš©ìê°€ ë°ì´í„°ì…‹ì„ ì €ì¥í•œ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”)
    base_path = './cats_and_dogs_filtered'  # í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì••ì¶• í•´ì œí–ˆë‹¤ê³  ê°€ì •

# ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
if os.path.exists(base_path):
    print(f"âœ… ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸: {base_path}")
    
    # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ê²½ë¡œ ì„¤ì •
    train_dir = os.path.join(base_path, 'train')
    validation_dir = os.path.join(base_path, 'validation')
    
    # ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸
    print(f"\nğŸ“ ë°ì´í„°ì…‹ êµ¬ì¡°:")
    print(f"   í›ˆë ¨ ë°ì´í„°: {train_dir}")
    if os.path.exists(train_dir):
        train_cats = len(os.listdir(os.path.join(train_dir, 'cats')))
        train_dogs = len(os.listdir(os.path.join(train_dir, 'dogs')))
        print(f"     - ê³ ì–‘ì´: {train_cats}ì¥")
        print(f"     - ê°œ: {train_dogs}ì¥")
    
    print(f"   ê²€ì¦ ë°ì´í„°: {validation_dir}")
    if os.path.exists(validation_dir):
        val_cats = len(os.listdir(os.path.join(validation_dir, 'cats')))
        val_dogs = len(os.listdir(os.path.join(validation_dir, 'dogs')))
        print(f"     - ê³ ì–‘ì´: {val_cats}ì¥")
        print(f"     - ê°œ: {val_dogs}ì¥")
else:
    print(f"âŒ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_path}")
    print("ğŸ“¥ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì••ì¶•ì„ í•´ì œí•´ì£¼ì„¸ìš”.")

# %% [markdown]
# ## B. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë°ì´í„°ì…‹ ìƒì„±

# %% [markdown]
# ### 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ì„¤ì •ê°’ ì •ì˜

# %%
# ğŸ›ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜
INPUT_SHAPE = (224, 224, 3)  # MobileNetV2 ì…ë ¥ í¬ê¸°
NUM_CLASSES = 2              # ê³ ì–‘ì´(0), ê°œ(1)
BATCH_SIZE = 32              # ë°°ì¹˜ í¬ê¸°
IMAGE_SIZE = (224, 224)      # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ í¬ê¸°
LEARNING_RATE = 0.0003       # í•™ìŠµë¥ 
EPOCHS = 10                  # í•™ìŠµ ì—í­ ìˆ˜

print("âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ!")
print(f"   - ì…ë ¥ í¬ê¸°: {INPUT_SHAPE}")
print(f"   - í´ë˜ìŠ¤ ìˆ˜: {NUM_CLASSES}")
print(f"   - ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
print(f"   - í•™ìŠµë¥ : {LEARNING_RATE}")
print(f"   - ì—í­ ìˆ˜: {EPOCHS}")

# %% [markdown]
# ### 2. ë°ì´í„°ì…‹ ìƒì„± ë° ì „ì²˜ë¦¬

# %%
# ğŸ—‚ï¸ í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„±
# image_dataset_from_directory: í´ë” êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ ë¼ë²¨ë§
train_ds = tf.keras.utils.image_dataset_from_directory(
    directory=train_dir,
    label_mode="binary",        # ì´ì§„ ë¶„ë¥˜ (ê³ ì–‘ì´=0, ê°œ=1)
    batch_size=BATCH_SIZE,
    image_size=IMAGE_SIZE,      # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    seed=42,                    # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ
    shuffle=True,               # ë°ì´í„° ì…”í”Œë§
)

# ğŸ—‚ï¸ ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±
test_ds = tf.keras.utils.image_dataset_from_directory(
    directory=validation_dir,
    label_mode="binary",
    batch_size=BATCH_SIZE,
    image_size=IMAGE_SIZE,
    seed=42,
    shuffle=False,              # ê²€ì¦ ë°ì´í„°ëŠ” ì…”í”Œí•˜ì§€ ì•ŠìŒ
)

print("âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
print(f"   - í›ˆë ¨ ë°ì´í„°: {len(train_ds)} ë°°ì¹˜")
print(f"   - ê²€ì¦ ë°ì´í„°: {len(test_ds)} ë°°ì¹˜")

# í´ë˜ìŠ¤ ì´ë¦„ í™•ì¸
class_names = train_ds.class_names
print(f"   - í´ë˜ìŠ¤: {class_names}")

# %% [markdown]
# ### 3. ë°ì´í„° ì‹œê°í™”

# %%
# ğŸ“Š ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™”
plt.figure(figsize=(15, 10))
for images, labels in train_ds.take(1):  # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ ê°€ì ¸ì˜¤ê¸°
    for i in range(min(20, len(images))):  # ìµœëŒ€ 20ê°œ ì´ë¯¸ì§€ í‘œì‹œ
        ax = plt.subplot(4, 5, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        
        # ë¼ë²¨ì„ í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
        label_idx = int(labels[i].numpy())
        plt.title(f'{class_names[label_idx]}', fontsize=12)
        plt.axis("off")

plt.suptitle('ğŸ–¼ï¸ í›ˆë ¨ ë°ì´í„° ìƒ˜í”Œ', fontsize=16, y=1.02)
plt.tight_layout()
plt.show()

# %% [markdown]
# ## C. MobileNetV2 Transfer Learning ëª¨ë¸ êµ¬ì¶•

# %% [markdown]
# ### 1. ì‚¬ì „í›ˆë ¨ëœ MobileNetV2 ëª¨ë¸ ë¡œë“œ

# %%
# ğŸ§  MobileNetV2 ì‚¬ì „í›ˆë ¨ ëª¨ë¸ ë¡œë“œ
# ImageNetìœ¼ë¡œ ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©, ë¶„ë¥˜ì¸µ(top layer) ì œì™¸
base_model = tf.keras.applications.MobileNetV2(
    input_shape=INPUT_SHAPE,
    weights='imagenet',    # ImageNet ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜
    include_top=False      # ìµœìƒìœ„ ë¶„ë¥˜ì¸µ ì œì™¸ (ìš°ë¦¬ê°€ ì§ì ‘ ì¶”ê°€í•  ì˜ˆì •)
)

print("ğŸ”„ MobileNetV2 ì‚¬ì „í›ˆë ¨ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
print(f"   - ì´ ë ˆì´ì–´ ìˆ˜: {len(base_model.layers)}")
print(f"   - ì¶œë ¥ í˜•íƒœ: {base_model.output_shape}")

# ğŸ”’ ë² ì´ìŠ¤ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³ ì • (Transfer Learning)
# ì‚¬ì „í›ˆë ¨ëœ íŠ¹ì„± ì¶”ì¶œê¸°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ìƒˆë¡œìš´ ë¶„ë¥˜ì¸µë§Œ í•™ìŠµ
base_model.trainable = False
print("ğŸ”’ ë² ì´ìŠ¤ ëª¨ë¸ ê°€ì¤‘ì¹˜ ê³ ì • ì™„ë£Œ!")

# %% [markdown]
# ### 2. ì „ì²´ ëª¨ë¸ êµ¬ì¶•

# %%
# ğŸ—ï¸ ì „ì²´ ëª¨ë¸ êµ¬ì¶•
# Sequential API ëŒ€ì‹  Functional API ì‚¬ìš©ìœ¼ë¡œ ë” ìœ ì—°í•œ ëª¨ë¸ êµ¬ì„±

inputs = tf.keras.Input(shape=INPUT_SHAPE)

# 1ï¸âƒ£ ì „ì²˜ë¦¬ ë ˆì´ì–´: í”½ì…€ ê°’ì„ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
# MobileNetV2ëŠ” [-1, 1] ë²”ìœ„ì˜ ì…ë ¥ì„ ê¸°ëŒ€í•¨
x = tf.keras.layers.Rescaling(1./127.5, offset=-1)(inputs)

# 2ï¸âƒ£ ì‚¬ì „í›ˆë ¨ëœ MobileNetV2 íŠ¹ì„± ì¶”ì¶œ
# training=False: ë°°ì¹˜ ì •ê·œí™” ë ˆì´ì–´ë¥¼ ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •
x = base_model(x, training=False)

# 3ï¸âƒ£ ì „ì—­ í‰ê·  í’€ë§: (7, 7, 1280) â†’ (1280,)
# ê° íŠ¹ì„± ë§µì˜ í‰ê· ê°’ì„ ê³„ì‚°í•˜ì—¬ ì°¨ì› ì¶•ì†Œ
x = tf.keras.layers.GlobalAveragePooling2D()(x)

# 4ï¸âƒ£ ë“œë¡­ì•„ì›ƒ: ê³¼ì í•© ë°©ì§€
x = tf.keras.layers.Dropout(0.2)(x)

# 5ï¸âƒ£ ì¶œë ¥ì¸µ: ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™”
output = tf.keras.layers.Dense(1, activation='sigmoid')(x)

# 6ï¸âƒ£ ëª¨ë¸ ìƒì„±
model = tf.keras.Model(inputs=inputs, outputs=output)

print("ğŸ—ï¸ ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ!")
model.summary()

# %% [markdown]
# ### 3. ëª¨ë¸ ì»´íŒŒì¼

# %%
# âš™ï¸ ëª¨ë¸ ì»´íŒŒì¼
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),  # Adam ì˜µí‹°ë§ˆì´ì €
    loss='binary_crossentropy',      # ì´ì§„ ë¶„ë¥˜ ì†ì‹¤ í•¨ìˆ˜
    metrics=['accuracy']             # í‰ê°€ ì§€í‘œ
)

print("âš™ï¸ ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ!")
print(f"   - ì˜µí‹°ë§ˆì´ì €: Adam (lr={LEARNING_RATE})")
print(f"   - ì†ì‹¤ í•¨ìˆ˜: Binary Crossentropy")
print(f"   - í‰ê°€ ì§€í‘œ: Accuracy")

# %% [markdown]
# ## D. ì½œë°± í•¨ìˆ˜ ì„¤ì •

# %%
# ğŸ“ ì½œë°± í•¨ìˆ˜ ì„¤ì •
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# 1ï¸âƒ£ ì¡°ê¸° ì¢…ë£Œ: ê²€ì¦ ì†ì‹¤ì´ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµ ì¤‘ë‹¨
early_stopping = EarlyStopping(
    monitor='val_loss',    # ëª¨ë‹ˆí„°ë§í•  ì§€í‘œ
    mode='min',            # ìµœì†Ÿê°’ì„ ì¶”ì 
    verbose=1,             # ë¡œê·¸ ì¶œë ¥
    patience=5,            # 5 ì—í­ ë™ì•ˆ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì¤‘ë‹¨
    restore_best_weights=True  # ìµœê³  ì„±ëŠ¥ ê°€ì¤‘ì¹˜ë¡œ ë³µì›
)

# 2ï¸âƒ£ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
checkpoint_path = "best_mobilenetv2_cats_dogs.keras"
model_checkpoint = ModelCheckpoint(
    filepath=checkpoint_path,
    save_best_only=True,   # ìµœê³  ì„±ëŠ¥ì¼ ë•Œë§Œ ì €ì¥
    monitor='val_accuracy', # ê²€ì¦ ì •í™•ë„ ê¸°ì¤€
    mode='max',            # ìµœëŒ“ê°’ì„ ì¶”ì 
    verbose=1
)

# 3ï¸âƒ£ í•™ìŠµë¥  ê°ì†Œ: ì„±ëŠ¥ ê°œì„ ì´ ë©ˆì¶”ë©´ í•™ìŠµë¥  ê°ì†Œ
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,            # í•™ìŠµë¥ ì„ ì ˆë°˜ìœ¼ë¡œ ê°ì†Œ
    patience=3,            # 3 ì—í­ ë™ì•ˆ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ê°ì†Œ
    min_lr=1e-7,          # ìµœì†Œ í•™ìŠµë¥ 
    verbose=1
)

callbacks = [early_stopping, model_checkpoint, reduce_lr]
print("ğŸ“ ì½œë°± í•¨ìˆ˜ ì„¤ì • ì™„ë£Œ!")

# %% [markdown]
# ## E. ëª¨ë¸ í•™ìŠµ

# %%
# ğŸ“ ëª¨ë¸ í•™ìŠµ ì‹œì‘
print("ğŸ“ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
print(f"   - ì—í­: {EPOCHS}")
print(f"   - ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
print("="*50)

history = model.fit(
    train_ds,                    # í›ˆë ¨ ë°ì´í„°
    validation_data=test_ds,     # ê²€ì¦ ë°ì´í„°
    epochs=EPOCHS,               # í•™ìŠµ ì—í­ ìˆ˜
    callbacks=callbacks,         # ì½œë°± í•¨ìˆ˜ë“¤
    verbose=1                    # í•™ìŠµ ê³¼ì • ì¶œë ¥
)

print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

# %% [markdown]
# ### ëª¨ë¸ ì €ì¥

# %%
# ğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ ë° ì €ì¥
print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")

# ì²´í¬í¬ì¸íŠ¸ì—ì„œ ìµœê³  ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë¡œë“œ
if os.path.exists(checkpoint_path):
    model.load_weights(checkpoint_path)
    print(f"âœ… ìµœê³  ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë¡œë“œ: {checkpoint_path}")

# ì „ì²´ ëª¨ë¸ ì €ì¥ (ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ)
model.save('cats_dogs_mobilenetv2_complete_model.keras')  # Keras ë„¤ì´í‹°ë¸Œ í˜•ì‹ (ê¶Œì¥)
model.save('cats_dogs_mobilenetv2_complete_model.h5')     # HDF5 í˜•ì‹
# SavedModel í˜•ì‹ìœ¼ë¡œë„ ì €ì¥ (TensorFlow Serving ë“±ì—ì„œ ì‚¬ìš©)
model.export('cats_dogs_mobilenetv2_savedmodel')

print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
print("   - Keras ë„¤ì´í‹°ë¸Œ í˜•ì‹: cats_dogs_mobilenetv2_complete_model.keras")
print("   - HDF5 í˜•ì‹: cats_dogs_mobilenetv2_complete_model.h5")
print("   - SavedModel í˜•ì‹: cats_dogs_mobilenetv2_savedmodel")

# %% [markdown]
# ## F. í•™ìŠµ ê²°ê³¼ ë¶„ì„

# %% [markdown]
# ### 1. í•™ìŠµ ê³¡ì„  ì‹œê°í™”

# %%
# ğŸ“ˆ í•™ìŠµ ê³¡ì„  ì‹œê°í™”
def plot_training_history(history):
    """í•™ìŠµ íˆìŠ¤í† ë¦¬ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # ì •í™•ë„ ê³¡ì„ 
    ax1.plot(history.history['accuracy'], label='í›ˆë ¨ ì •í™•ë„', marker='o')
    ax1.plot(history.history['val_accuracy'], label='ê²€ì¦ ì •í™•ë„', marker='s')
    ax1.set_title('ğŸ“Š ëª¨ë¸ ì •í™•ë„', fontsize=14)
    ax1.set_xlabel('ì—í­')
    ax1.set_ylabel('ì •í™•ë„')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # ì†ì‹¤ ê³¡ì„ 
    ax2.plot(history.history['loss'], label='í›ˆë ¨ ì†ì‹¤', marker='o')
    ax2.plot(history.history['val_loss'], label='ê²€ì¦ ì†ì‹¤', marker='s')
    ax2.set_title('ğŸ“‰ ëª¨ë¸ ì†ì‹¤', fontsize=14)
    ax2.set_xlabel('ì—í­')
    ax2.set_ylabel('ì†ì‹¤')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # ìµœê³  ì„±ëŠ¥ ì¶œë ¥
    best_train_acc = max(history.history['accuracy'])
    best_val_acc = max(history.history['val_accuracy'])
    print(f"ğŸ† ìµœê³  í›ˆë ¨ ì •í™•ë„: {best_train_acc:.4f}")
    print(f"ğŸ† ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.4f}")

# í•™ìŠµ ê³¡ì„  ê·¸ë¦¬ê¸°
plot_training_history(history)

# %% [markdown]
# ### 2. ëª¨ë¸ í‰ê°€

# %%
# ğŸ“Š ëª¨ë¸ í‰ê°€
print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")

# ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ í‰ê°€
test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)
print(f"âœ… ìµœì¢… ê²€ì¦ ì •í™•ë„: {test_accuracy:.4f}")
print(f"âœ… ìµœì¢… ê²€ì¦ ì†ì‹¤: {test_loss:.4f}")

# %% [markdown]
# ## G. ì˜ˆì¸¡ ë° ê²°ê³¼ ë¶„ì„

# %% [markdown]
# ### 1. ë°°ì¹˜ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸

# %%
# ğŸ”® ë°°ì¹˜ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
print("ğŸ”® ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì¤‘...")

# ê²€ì¦ ë°ì´í„°ì—ì„œ í•œ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
batch_images, batch_labels = next(iter(test_ds))
print(f"ë°°ì¹˜ í¬ê¸°: {batch_images.shape[0]}")

# ì˜ˆì¸¡ ìˆ˜í–‰
predictions = model.predict(batch_images, verbose=0)
predicted_classes = (predictions > 0.5).astype(int).flatten()

# ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(20, 15))
for i in range(min(16, len(batch_images))):  # ìµœëŒ€ 16ê°œ ì´ë¯¸ì§€ í‘œì‹œ
    ax = plt.subplot(4, 4, i + 1)
    
    # ì´ë¯¸ì§€ í‘œì‹œ (ì •ê·œí™”ëœ ì´ë¯¸ì§€ë¥¼ ì›ë˜ ë²”ìœ„ë¡œ ë³µì›)
    img = batch_images[i].numpy()
    img = (img + 1) / 2  # [-1, 1] â†’ [0, 1]
    plt.imshow(img)
    
    # ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ë¼ë²¨ ë¹„êµ
    true_label = int(batch_labels[i].numpy())
    pred_label = predicted_classes[i]
    confidence = predictions[i][0]
    
    # ì œëª© ì„¤ì • (ë§ìœ¼ë©´ ì´ˆë¡ìƒ‰, í‹€ë¦¬ë©´ ë¹¨ê°„ìƒ‰)
    color = 'green' if true_label == pred_label else 'red'
    title = f'ì‹¤ì œ: {class_names[true_label]}\nì˜ˆì¸¡: {class_names[pred_label]}\nì‹ ë¢°ë„: {confidence:.3f}'
    plt.title(title, color=color, fontsize=10)
    plt.axis('off')

plt.suptitle('ğŸ”® ì˜ˆì¸¡ ê²°ê³¼ (ì´ˆë¡ìƒ‰: ì •ë‹µ, ë¹¨ê°„ìƒ‰: ì˜¤ë‹µ)', fontsize=16, y=1.02)
plt.tight_layout()
plt.show()

# ì •í™•ë„ ê³„ì‚°
correct_predictions = np.sum(predicted_classes == batch_labels.numpy())
batch_accuracy = correct_predictions / len(batch_labels)
print(f"ğŸ“Š ë°°ì¹˜ ì •í™•ë„: {batch_accuracy:.4f} ({correct_predictions}/{len(batch_labels)})")

# %% [markdown]
# ### 2. ê°œë³„ ì´ë¯¸ì§€ ì˜ˆì¸¡ í•¨ìˆ˜

# %%
def predict_single_image(model, image_path, class_names):
    """
    ê°œë³„ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        model: í›ˆë ¨ëœ ëª¨ë¸
        image_path: ì˜ˆì¸¡í•  ì´ë¯¸ì§€ ê²½ë¡œ
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        predicted_class: ì˜ˆì¸¡ëœ í´ë˜ìŠ¤
        confidence: ì˜ˆì¸¡ ì‹ ë¢°ë„
    """
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        img = tf.keras.utils.load_img(image_path, target_size=IMAGE_SIZE)
        img_array = tf.keras.utils.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        prediction = model.predict(img_array, verbose=0)
        confidence = prediction[0][0]
        predicted_class = class_names[int(confidence > 0.5)]
        
        return predicted_class, confidence
        
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

# ì˜ˆì¸¡ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ (ê²€ì¦ ë°ì´í„°ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¡œ)
if os.path.exists(validation_dir):
    # ê³ ì–‘ì´ ì´ë¯¸ì§€ í•˜ë‚˜ ì„ íƒ
    cat_images = glob(os.path.join(validation_dir, 'cats', '*.jpg'))
    if cat_images:
        test_image_path = cat_images[0]
        predicted_class, confidence = predict_single_image(model, test_image_path, class_names)
        print(f"ğŸ”® ê°œë³„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸:")
        print(f"   ì´ë¯¸ì§€: {os.path.basename(test_image_path)}")
        print(f"   ì˜ˆì¸¡: {predicted_class}")
        print(f"   ì‹ ë¢°ë„: {confidence:.4f}")

# %% [markdown]
# ### 3. ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ì˜ˆì¸¡

# %%
def predict_images_in_directory(model, directory_path, class_names, batch_size=32):
    """
    ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•´ ë°°ì¹˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        model: í›ˆë ¨ëœ ëª¨ë¸
        directory_path: ì˜ˆì¸¡í•  ì´ë¯¸ì§€ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        batch_size: ë°°ì¹˜ í¬ê¸°
    
    Returns:
        results: [(íŒŒì¼ëª…, ì˜ˆì¸¡_í´ë˜ìŠ¤, ì‹ ë¢°ë„)] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸ“ ë””ë ‰í† ë¦¬ ì˜ˆì¸¡ ì‹œì‘: {directory_path}")
    
    # ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì
    image_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.gif')
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
    image_files = []
    image_arrays = []
    
    for filename in os.listdir(directory_path):
        if filename.lower().endswith(image_extensions):
            img_path = os.path.join(directory_path, filename)
            
            try:
                # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
                img = tf.keras.utils.load_img(img_path, target_size=IMAGE_SIZE)
                img_array = tf.keras.utils.img_to_array(img)
                
                image_files.append(filename)
                image_arrays.append(img_array)
                
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {filename} - {e}")
                continue
    
    if not image_arrays:
        print("âŒ ì˜ˆì¸¡í•  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ numpy ë°°ì—´ë¡œ ë³€í™˜
    image_arrays = np.array(image_arrays)
    print(f"ğŸ“Š ì´ {len(image_arrays)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
    
    # ë°°ì¹˜ ì˜ˆì¸¡ ìˆ˜í–‰
    predictions = model.predict(image_arrays, batch_size=batch_size, verbose=1)
    
    # ê²°ê³¼ ìƒì„±
    results = []
    for filename, pred in zip(image_files, predictions):
        confidence = pred[0]
        predicted_class = class_names[int(confidence > 0.5)]
        results.append((filename, predicted_class, confidence))
    
    return results

# ê³ ì–‘ì´ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰
if os.path.exists(validation_dir):
    cat_test_dir = os.path.join(validation_dir, 'cats')
    if os.path.exists(cat_test_dir):
        print("ğŸ± ê³ ì–‘ì´ ì´ë¯¸ì§€ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸:")
        cat_results = predict_images_in_directory(model, cat_test_dir, class_names)
        
        # ê²°ê³¼ ë¶„ì„
        correct_predictions = sum(1 for _, pred_class, _ in cat_results if pred_class == 'cats')
        total_predictions = len(cat_results)
        accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
        
        print(f"ğŸ“Š ê³ ì–‘ì´ ì˜ˆì¸¡ ê²°ê³¼:")
        print(f"   - ì´ ì´ë¯¸ì§€: {total_predictions}ê°œ")
        print(f"   - ì •í™•í•œ ì˜ˆì¸¡: {correct_predictions}ê°œ")
        print(f"   - ì •í™•ë„: {accuracy:.4f}")
        
        # ì²˜ìŒ 5ê°œ ê²°ê³¼ ì¶œë ¥
        print(f"   - ìƒ˜í”Œ ê²°ê³¼:")
        for i, (filename, pred_class, confidence) in enumerate(cat_results[:5]):
            print(f"     {i+1}. {filename}: {pred_class} (ì‹ ë¢°ë„: {confidence:.3f})")

# %% [markdown]
# ### 4. ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥

# %%
def save_predictions_to_csv(results, output_filename):
    """
    ì˜ˆì¸¡ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        results: [(íŒŒì¼ëª…, ì˜ˆì¸¡_í´ë˜ìŠ¤, ì‹ ë¢°ë„)] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
        output_filename: ì¶œë ¥ íŒŒì¼ëª…
    """
    if not results:
        print("âŒ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # DataFrame ìƒì„±
    df = pd.DataFrame(results, columns=['filename', 'predicted_class', 'confidence'])
    
    # CSV íŒŒì¼ë¡œ ì €ì¥
    df.to_csv(output_filename, index=False, encoding='utf-8-sig')
    
    print(f"ğŸ’¾ ê²°ê³¼ê°€ {output_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š ì €ì¥ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
    print(df.head())
    
    # ì˜ˆì¸¡ í´ë˜ìŠ¤ë³„ ê°œìˆ˜ í™•ì¸
    print(f"\nğŸ“ˆ ì˜ˆì¸¡ í´ë˜ìŠ¤ë³„ ê°œìˆ˜:")
    print(df['predicted_class'].value_counts())
    
    # ì‹ ë¢°ë„ í†µê³„
    print(f"\nğŸ“Š ì‹ ë¢°ë„ í†µê³„:")
    print(f"   - í‰ê· : {df['confidence'].mean():.4f}")
    print(f"   - ìµœëŒ€: {df['confidence'].max():.4f}")
    print(f"   - ìµœì†Œ: {df['confidence'].min():.4f}")

# ê³ ì–‘ì´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ (ìœ„ì—ì„œ ì‹¤í–‰í–ˆë‹¤ë©´)
if 'cat_results' in locals() and cat_results:
    save_predictions_to_csv(cat_results, 'cats_predictions.csv')

# %% [markdown]
# ## H. í”„ë¡œì íŠ¸ ìš”ì•½ ë° í•™ìŠµ ë‚´ìš©

# %%
print("ğŸ‰ í”„ë¡œì íŠ¸ ì™„ë£Œ!")
print("="*60)
print("ğŸ“š í•™ìŠµí•œ ì£¼ìš” ë‚´ìš©:")
print("="*60)

print("1ï¸âƒ£ Transfer Learning ê°œë…ê³¼ í™œìš©")
print("   - ì‚¬ì „í›ˆë ¨ëœ MobileNetV2 ëª¨ë¸ í™œìš©")
print("   - ImageNet ê°€ì¤‘ì¹˜ë¥¼ ê³ ì–‘ì´/ê°œ ë¶„ë¥˜ì— ì „ì´")
print("   - ê³„ì‚° ë¹„ìš© ì ˆì•½ê³¼ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±")

print("\n2ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬ ê¸°ë²•")
print("   - image_dataset_from_directoryë¥¼ í™œìš©í•œ ìë™ ë¼ë²¨ë§")
print("   - ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•ê³¼ ì •ê·œí™”")
print("   - ë°°ì¹˜ ì²˜ë¦¬ì™€ ë°ì´í„° ì…”í”Œë§")

print("\n3ï¸âƒ£ ëª¨ë¸ êµ¬ì¶• ê¸°ë²•")
print("   - Functional APIë¥¼ í™œìš©í•œ ìœ ì—°í•œ ëª¨ë¸ êµ¬ì„±")
print("   - ì „ì²˜ë¦¬ ë ˆì´ì–´ í†µí•©")
print("   - GlobalAveragePoolingê³¼ Dropout í™œìš©")

print("\n4ï¸âƒ£ í•™ìŠµ ìµœì í™” ê¸°ë²•")
print("   - EarlyStoppingìœ¼ë¡œ ê³¼ì í•© ë°©ì§€")
print("   - ModelCheckpointë¡œ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥")
print("   - ReduceLROnPlateauë¡œ í•™ìŠµë¥  ì¡°ì •")

print("\n5ï¸âƒ£ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”")
print("   - í•™ìŠµ ê³¡ì„  ë¶„ì„")
print("   - ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”")
print("   - ë°°ì¹˜ ì˜ˆì¸¡ê³¼ ê°œë³„ ì˜ˆì¸¡ êµ¬í˜„")

print("\nğŸ¯ ì‹¤ë¬´ í™œìš© í¬ì¸íŠ¸:")
print("   - ì ì€ ë°ì´í„°ë¡œë„ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±")
print("   - ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ ê°€ëŠ¥")
print("   - ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì— ì‘ìš© ê°€ëŠ¥")

print("\nâœ… ë‹¤ìŒ ë‹¨ê³„ í•™ìŠµ ê¶Œì¥ì‚¬í•­:")
print("   - Fine-tuning: ì‚¬ì „í›ˆë ¨ ëª¨ë¸ì˜ ì¼ë¶€ ë ˆì´ì–´ í•™ìŠµ")
print("   - Data Augmentation: ë°ì´í„° ì¦ê°• ê¸°ë²• ì ìš©")
print("   - ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œ ë„ì „")
print("   - ë‹¤ë¥¸ ì‚¬ì „í›ˆë ¨ ëª¨ë¸ (ResNet, EfficientNet ë“±) ë¹„êµ")

print("="*60)
print("ğŸš€ ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤! ì„±ê³µì ìœ¼ë¡œ Transfer Learningì„ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤!")


